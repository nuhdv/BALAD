# -*- coding: utf-8 -*-
import numpy as np
import torch
import random
import time
from abc import ABCMeta, abstractmethod
from utils import get_sub_seqs
from tqdm import tqdm

class BaseDeepAD(metaclass=ABCMeta):
    """
    Abstract class for deep outlier detection models

    Parameters
    ----------
    epochs: int, optional (default=100)
        Number of training epochs

    batch_size: int, optional (default=64)
        Number of samples in a mini-batch

    lr: float, optional (default=1e-3)
        Learning rate

    n_ensemble: int or str, optional (default=1)
        Number of ensemble size

    seq_len: int, optional (default=100)
        Size of window used to create subsequences from the data

    stride: int, optional (default=1)
        number of time points the window will move between two subsequences

    epoch_steps: int, optional (default=-1)
        Maximum steps in an epoch
            - If -1, all the batches will be processed

    prt_steps: int, optional (default=10)
        Number of epoch intervals per printing

    device: str, optional (default='cuda')
        torch device,

    contamination : float in (0., 0.5), optional (default=0.1)
        The amount of contamination of the data set,
        i.e. the proportion of outliers in the data set. Used when fitting to
        define the threshold on the decision function.

    verbose: int, optional (default=1)
        Verbosity mode

    random_stateï¼š int, optional (default=42)
        the seed used by the random

    Attributes
    ----------
    decision_scores_ : numpy array of shape (n_samples,)
        The outlier scores of the training data.
        The higher, the more abnormal. Outliers tend to have higher
        scores. This value is available once the detector is fitted.

    threshold_ : float
        The threshold is based on ``contamination``. It is the
        ``n_samples * contamination`` most abnormal samples in
        ``decision_scores_``. The threshold is calculated for generating
        binary outlier labels.

    labels_ : int, either 0 or 1
        The binary labels of the training data. 0 stands for inliers
        and 1 for outliers/anomalies. It is generated by applying
        ``threshold_`` on ``decision_scores_``.

    """
    def __init__(self, model_name,
                 epochs=100, batch_size=64, lr=1e-3,
                 n_ensemble=1, seq_len=100, stride=1,
                 epoch_steps=-1, prt_steps=10,
                 device='cuda', contamination=0.1,
                 verbose=1, random_state=42):
        self.model_name = model_name

        self.seq_len = seq_len
        self.stride = stride

        self.epochs = epochs
        self.batch_size = batch_size
        self.lr = lr

        self.device = device
        self.contamination = contamination

        self.epoch_steps = epoch_steps
        self.prt_steps = prt_steps
        self.verbose = verbose

        self.n_features = -1
        self.n_samples = -1
        self.criterion = None
        self.net = None

        self.n_ensemble = n_ensemble

        self.train_loader = None
        self.test_loader = None

        self.epoch_time = None

        self.train_data = None
        self.train_label = None

        self.decision_scores_ = None
        self.labels_ = None
        self.threshold_ = None

        self.random_state = random_state
        self.set_seed(random_state)
        return

    def fit(self, X, y=None):
        """
        Fit detector. y is ignored in unsupervised methods.

        Parameters
        ----------
        X : numpy array of shape (n_samples, n_features)
            The input samples.

        y : numpy array of shape (n_samples, )
            Not used in unsupervised methods, present for API consistency by convention.
            used in (semi-/weakly-) supervised methods

        Returns
        -------
        self : object
            Fitted estimator.
        """

        X_seqs = get_sub_seqs(X, seq_len=self.seq_len, stride=self.stride)
        # y_seqs = get_sub_seqs_label(y, seq_len=self.seq_len, stride=self.stride) if y is not None else None
        y_seqs = y
        self.train_data = X_seqs
        self.train_label = y_seqs
        self.n_samples, self.n_features = X_seqs.shape[0], X_seqs.shape[2]

        if self.verbose >= 1:
            print('Start Training...')

        self.train_loader, self.net, self.criterion = self.training_prepare(self.train_data,
                                                                            y=self.train_label)
        self._training()

        return self

    def decision_function(self, X, label, return_rep=False):
        """Predict raw anomaly scores of X using the fitted detector.

        The anomaly score of an input sample is computed based on the fitted
        detector. For consistency, outliers are assigned with
        higher anomaly scores.

        Parameters
        ----------
        X : numpy array of shape (n_samples, n_features)
            The input samples. Sparse matrices are accepted only
            if they are supported by the base estimator.

        label: numpy array of shape (n_samples, )
               The input label. used to query.

        return_rep: boolean, optional, default=False
            whether return representations

        Returns
        -------
        anomaly_scores : numpy array of shape (n_samples,)
            The anomaly score of the input samples.
        """

        X = get_sub_seqs(X, seq_len=self.seq_len, stride=self.stride)

        representations = []
        s_final = np.zeros(X.shape[0])
        for _ in range(self.n_ensemble):
            self.test_loader = self.inference_prepare(X, label)

            z, scores = self._inference()
            s_final += scores
            representations.extend(z)
        representations = np.array(representations)

        if return_rep:
            return s_final, representations
        else:
            return s_final

    def _training(self):
        optimizer = torch.optim.Adam(self.net.parameters(),
                                     lr=self.lr,
                                     weight_decay=1e-5)

        self.net.train()
        warm_up = int(0.5 * self.epochs)
        for epoch in range(self.epochs):
            t1 = time.time()
            total_loss = 0
            cnt = 0
            for batch_x in self.train_loader:
                loss = self.training_forward(batch_x, self.net, self.criterion, True if epoch >= warm_up else False) ##warm_up_epochs
                self.net.zero_grad()
                loss.backward()
                optimizer.step()
                total_loss += loss.item()
                cnt += 1

                # terminate this epoch when reaching assigned maximum steps per epoch
                if cnt > self.epoch_steps != -1:
                    break
            t = time.time() - t1
            if self.verbose >= 1 and (epoch == 0 or (epoch+1) % self.prt_steps == 0):
                print(f'epoch{epoch+1:3d}, '
                      f'training loss: {total_loss/cnt:.6f}, '
                      f'time: {t:.1f}s')

            if epoch == 0:
                self.epoch_time = t

            self.epoch_update()

        return

    def _inference(self):
        z_lst = []
        score_lst = []

        optimizer = torch.optim.Adam(self.net.parameters(),
                                     lr=self.lr,
                                     weight_decay=1e-5)
        if self.verbose >= 2:
            _iter_ = tqdm(self.test_loader, desc='testing: ')
        else:
            _iter_ = self.test_loader

        for batch_x, batch_label in _iter_:
            batch_z, s = self.inference_forward(batch_x, batch_label, self.net, self.criterion, optimizer)
            z_lst.append(batch_z)
            score_lst.append(s)

        z = torch.cat(z_lst).data.cpu().numpy()
        scores = torch.cat(score_lst).data.cpu().numpy()

        return z, scores

    @abstractmethod
    def training_forward(self, batch_x, net, criterion, up_R):
        """define forward step in training"""
        pass

    @abstractmethod
    def inference_forward(self, batch_x, batch_label, net, criterion, optimizer):
        """define forward and adapt step in inference"""
        pass

    @abstractmethod
    def training_prepare(self, X, y):
        """define train_loader, net, and criterion"""
        pass

    @abstractmethod
    def inference_prepare(self, X, y):
        """define test_loader"""
        pass

    def epoch_update(self):
        """for any updating operation after each training epoch"""
        return

    @staticmethod
    def set_seed(seed):
        torch.manual_seed(seed)
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        np.random.seed(seed)
        random.seed(seed)
        # torch.backends.cudnn.benchmark = False
        # torch.backends.cudnn.deterministic = True
